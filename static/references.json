{
    "references" : [
        {
            "name" : "Bradbury, J. (2017). Biomimicry: Analysis of a corpus-based interactive improvisational system. In *In International Computer Music Conference* (pp. 174-178). Michigan Publishing, University of Michigan Library. http://hdl.handle.net/2027/spo.bbp2372.2017.027",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2017.027"
        },
        {
            "name" : "Bradbury, J. (2020). Computer-assisted corpus exploration with UMAP and agglomerative clustering. In *Proceedings of the 1st Joint Conference on AI Music Creativity* (p. 4). AIMC. http://doi.org/10.5281/zenodo.4285398",
            "url" : "http://doi.org/10.5281/zenodo.4285398"
        },
        {
            "name" : "Tremblay, P. A., Green, O., Roma, G., & Harker, A. (2019, March). From collections to corpora: Exploring sounds through fluid decomposition. In *International Computer Music Conference and New York City Electroacoustic Music Festival.* https://pure.hud.ac.uk/ws/files/17022941/towardscorpus_final.pdf",
            "url" : "https://pure.hud.ac.uk/ws/files/17022941/towardscorpus_final.pdf"
        },
        {
            "name" : "Lefèvre, S., & Vincent, N. (2011). A two level strategy for audio segmentation. *Digital Signal Processing, 21*(2), 270-277. https://hal.archives-ouvertes.fr/hal-00512744",
            "url" : "https://hal.archives-ouvertes.fr/hal-00512744"
        },
        {
            "name" : "Garber, L., y Ciencia, M. A., Ciccola, T., & Amusategui, J. C. (2020). AudioStellar, an open source corpus-based musical instrument for latent sound structure discovery and sonic experimentation. https://thegardenofcuriosity.untref.edu.ar/img/10_audiostellar/AudioStellar_for_ICMC2020.pdf",
            "url" : "https://thegardenofcuriosity.untref.edu.ar/img/10_audiostellar/AudioStellar_for_ICMC2020.pdf"
        },
        {
            "name" : "Vegeborn, V. H. (2020). *LjudMAP: A visualisation tool for exploring audio collections with real-time concatenative synthesis capabilities* [Master's thesis, KTH Royal Institute of Technology]. DiVA. http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-277831",   
            "url" : "http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-277831"
        },
        {
            "name" : "Esling, P., Masuda, N., Bardet, A., & Despres, R. (2019). Universal audio synthesizer control with normalizing flows. *arXiv preprint arXiv:1907.00971.*",
            "url" : "https://arxiv.org/pdf/1907.00971.pdf"
        },
        {
            "name" : "Fasciani, S. (2016). Interactive computation of timbre spaces for sound synthesis control. In *2nd International Symposium on Sound and Interactivity* (pp. 69-78). ICMA Array.",
            "url" : "https://ro.uow.edu.au/dubaipapers/751/"
        },
        {
            "name" : "McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., & Nieto, O. (2015, July). librosa: Audio and music signal analysis in python. In *Proceedings of the 14th Python in Science Conference* (Vol. 8, pp. 18-25). https://doi.org/10.25080/Majora-7b98e3ed-003 ",
            "url" : "https://doi.org/10.25080/Majora-7b98e3ed-003 "
        },
        {
            "name" : "Roma, G., Green, O., & Tremblay, P. A. (2019, June). Adaptive mapping of sound collections for data-driven musical interfaces. In *NIME* (pp. 313-318). http://doi.org/10.5281/zenodo.3672976",
            "url" : "http://doi.org/10.5281/zenodo.3672976"
        },
        {
            "name" : "Green, O. (2013). *User serviceable parts: Practice, technology, sociality and method in live electronic musicking* [Doctoral dissertation, City University London]. City Research Online. https://openaccess.city.ac.uk/id/eprint/2730/",
            "url" : "https://openaccess.city.ac.uk/id/eprint/2730/"
        },
        {
            "name" : "Parker, M. & Furniss, P., (2014). gruntCount (bass clarinet Edition): blurring the piece, system, instrument distinction. https://www.research.ed.ac.uk/en/publications/gruntcount-bass-clarinet-edition-blurring-the-piece-system-instru",
            "url" : "https://www.research.ed.ac.uk/en/publications/gruntcount-bass-clarinet-edition-blurring-the-piece-system-instru"
        },
        {
            "name" : "Puckette, M. (2015, March). Maximally uniform sequences from stochastic processes. In *Conference of the Society for Electro-Acoustic Music in the United States* (pp. 26-28).",
            "url" : "http://msp.ucsd.edu/Publications/seamus15.pdf"
        },
        {
            "name" : "Harker, A. (2012). Navigating sample-based music: Immediacy and musical control in recent electronic works. In *Symposium \"Les Espaces sonores – Stimmungen, Klanganalysen, spektrale Musiken\". http://eprints.hud.ac.uk/id/eprint/18608/1/AHarker_Navigating_Sample_Based_Music.pdf",
            "url" : "http://eprints.hud.ac.uk/id/eprint/18608/1/AHarker_Navigating_Sample_Based_Music.pdf"
        },
        {
            "name" : "Linson, A., Dobbyn, C., Lewis, G. E., & Laney, R. (2015). A subsumption agent for collaborative free improvisation. *Computer Music Journal, 39*(4), 96-115.",
            "url" : "http://libeprints.open.ac.uk/46072/1/__userdata_documents2_dld2_Desktop_A%20Subsumption%20Agent%20for%20Collaborative%20Free%20Improvisation.pdf"
        },
        {
            "name" : "McInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. *arXiv preprint arXiv:1802.03426*.",
            "url" : "https://arxiv.org/abs/1802.03426"
        },
        {
            "name" : "Anderberg, M. R. (1973). The broad view of cluster analysis. *Cluster analysis for applications*, 1-9. https://doi.org/10.1016/B978-0-12-057650-0.50007-7",
            "url" : "https://doi.org/10.1016/B978-0-12-057650-0.50007-7"
        },
        {
            "name" : "Xu, R., & Wunsch, D. (2008). Cluster Analysis. In R. Xu and D.C. Wunsch (Eds.), .*Clustering* (pp. 1-15). John Wiley & Sons. https://doi.org/10.1002/9780470382776.ch1",
            "url" : "https://doi.org/10.1002/9780470382776.ch1"
        },
        {
            "name" : "Agostini, A., & Ghisi, D. (2012). Bach: An environment for computer-aided composition in Max. In *ICMC* (pp. 373-378). http://hdl.handle.net/2027/spo.bbp2372.2012.068",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2012.068"
        },
        {
            "name" : "Ghisi, D. (n.d.). *Bach*. Bach Project. Retrieved April 14, 2021 from https://www.bachproject.net/",
            "url" : "https://www.bachproject.net/"
        },
        {
            "name" : "Bresson, J., Bouche, D., Carpentier, T., Schwarz, D., & Garcia, J. (2017). Next-generation computer-aided composition environment: A new implementation of OpenMusic. In *ICMC* (pp. 253-258). http://hdl.handle.net/2027/spo.bbp2372.2017.042 ",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2017.042"
        },
        {
            "name" : "Assayag, G., Rueda, C., Laurson, M., Agon, C., & Delerue, O. (1999). Computer-assisted composition at IRCAM: From PatchWork to OpenMusic. *Computer Music Journal*, 23(3), 59-72.",
            "url" : "https://www.jstor.org/stable/3681240"
        },
        {
            "name" : "Assayag, G. (1998, October). Computer assisted composition today. *1st Symposium On Music and Computers*",
            "url" : "https://www.music.mcgill.ca/~gary/306/week11/Assayag_ComputerAssisted_1998.pdf"
        },
        {
            "name" : "Ganis, F., Knudesn, E. F., Lyster, S. V., Otterbein, R., Südholt, D., & Erkut, C. (2021). Real-time timbre transfer and sound synthesis using DDSP. *arXiv preprint arXiv:2103.07220*.",
            "url" : "https://arxiv.org/abs/2103.07220"
        },
        {
            "name" : "Hadjeres, G., Pachet, F., & Nielsen, F. (2017, July). DeepBach: A steerable model for Bach chorales generation. *International Conference on Machine Learning* (pp. 1362-1371). PMLR.",
            "url" : "http://proceedings.mlr.press/v70/hadjeres17a/hadjeres17a.pdf"
        },
        {
            "name" : "Sturm, B. L., Santos, J. F., Ben-Tal, O., & Korshunova, I. (2016). Music transcription modelling and composition using deep learning. *arXiv preprint arXiv:1604.08723*.",
            "url" : "https://arxiv.org/abs/1604.08723"
        },
        {
            "name" : "Fiebrink, R., & Caramiaux, B. (2016). The machine learning algorithm as creative musical tool. *arXiv preprint arXiv:1611.00379*.",
            "url" : "https://arxiv.org/abs/1611.00379"
        },
        {
            "name" : "Mitchell, T. M. (1997). *Machine learning*, McGraw Hill. http://www.cs.cmu.edu/~tom/mlbook.html",
            "url" : "http://www.cs.cmu.edu/~tom/mlbook.html"
        },
        {
            "name" : "Mehri, S., Kumar, K., Gulrajani, I., Kumar, R., Jain, S., Sotelo, J., ... & Bengio, Y. (2016). SampleRNN: An unconditional end-to-end neural audio generation model. *arXiv preprint arXiv:1612.07837*.",
            "url" : "https://arxiv.org/abs/1612.07837"
        },
        {
            "name" : "Bischoff, J. (1991). Software as sculpture: Creating music from the ground up. *Leonardo Music Journal, 1*(1), 37-40. https://doi.org/10.2307/1513119",
            "url" : "https://doi.org/10.2307/1513119"
        },
        {
            "name" : "Wang, W. (Ed.). (2010). *Machine audition: Principles, algorithms and systems*. IGI Global. https://doi.org/10.4018/978-1-61520-919-4",
            "url" : "https://doi.org/10.4018/978-1-61520-919-4"
        },
        {
            "name" : "Bowers, J., Richards, J., Shaw, T., Frize, J., Freeth, B., Topley, S., ... & Edmondes, W. (2016). One knob to rule them all: Reductionist interfaces for expansionist research. In *NIME* (pp. 433-438). http://doi.org/10.5281/zenodo.1175996",
            "url" : "http://doi.org/10.5281/zenodo.1175996"
        },
        {
            "name" : "Malt, M., & Jourdan, E. (2008, July). Zsa.Descriptors: a library for real-time descriptors analysis. In *5th Sound and Music Computing Conference* (pp. 134-137).",
            "url" : "http://smc.afim-asso.org/smc08/images/proceedings/session7_number3_paper45.pdf"
        },
        {
            "name" : "Peeters, G. (2004). A large set of audio features for sound description (similarity and classification) in the CUIDADO project. *CUIDADO Ist Project Report, 54*(0), 1-25.",
            "url" : "http://recherche.ircam.fr/anasyn/peeters/ARTICLES/Peeters_2003_cuidadoaudiofeatures.pdf"
        },
        {
            "name" : "Tanaka, A. (2010). Mapping out instruments, affordances, and mobiles. In *NIME* (pp. 88-93). http://doi.org/10.5281/zenodo.1177903",
            "url" : "http://doi.org/10.5281/zenodo.1177903"
        },
        {
            "name" : "Varga, B. A. (1996). *Conversations with Xenakis*. Faber & Faber.",
            "url" : "https://www.faber.co.uk/9780571179596-conversations-with-iannis-xenakis.html"
        },
        {
            "name" : "Hunt, A., Wanderley, M. M., & Paradis, M. (2003). 'The importance of parameter mapping in electronic instrument design'. *Journal of New Music Research*, 32(4), 429-440.",
            "url" : "https://www.tandfonline.com/doi/abs/10.1076/jnmr.32.4.429.18853"
        },
        {
            "name" : "Kiefer, C. (2014). Musical Instrument Mapping Design with Echo State Networks. In *NIME* (pp. 293-298). http://doi.org/10.5281/zenodo.1178829",
            "url" : "http://doi.org/10.5281/zenodo.1178829"
        },
        {
            "name" : "Thomson, P. (2004). *Atoms and errors: Towards a history and aesthetics of microsound. Organised Sound, 9*(2), 207-218.",
            "url" : "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.8449&rep=rep1&type=pdf"
        },
        {
            "name" : "Briz, N. (n.d.). *From The Ground Up In Order, Embrace*. Vimeo. Retrieved 10 May, 2021, from https://vimeo.com/4506517",
            "url" : "https://vimeo.com/4506517"
        },
        {
            "name" : "Cascone, K. (n.d.). *microsound.org*. www.microsound.org.",
            "url" : "http://microsound.org"
        },
        {
            "name" : "Cascone, K. (2000). The aesthetics of failure: “Post-digital” tendencies in contemporary computer music. *Computer Music Journal, 24*(4), 12-18. https://doi.org/10.1162/014892600559489",
            "url" : "https://doi.org/10.1162/014892600559489"
        },
        {
            "name" : "Bergström, I., & Lotto, R. B. (2015). *Code Bending: A new creative coding practice. Leonardo, 48*(1), 25-31. https://doi.org/10.1162/LEON_a_00934",
            "url" : "https://doi.org/10.1162/LEON_a_00934"
        },
        {
            "name" : "Grisey, G. (1987). Tempus ex machina: A composer's reflections on musical time. *Contemporary music review*, 2(1), 239-275. https://doi.org/10.1080/07494468708567060",
            "url" : "https://doi.org/10.1080/07494468708567060"
        },
        {
            "name" : "Roads, C. (2012, May). From grains to forms. In M. Solomos (Eds.) *Proceedings of The International Symposium Xenakis. La Musique Electroacoustique/The Electroacoustic Music of Xenakis* (Vol. 8).",
            "url" : "https://clang.mat.ucsb.edu/clang/articles_files/From%20grains%20to%20forms.pdf"
        },
        {
            "name" : "Tenney, J. (2014). *From scratch: Writings in music theory.* University of Illinois Press.",
            "url" : "https://www.jstor.org/stable/10.5406/j.ctt6wr6t7"
        },
        {
            "name" : "Bertelsen, O. W., Breinbjerg, M., & Pold, S. (2009). Emerging materiality: Reflections on creative use of software in electronic music composition. *Leonardo, 42*(3), 197-202.",
            "url" : "https://www.mitpressjournals.org/doi/pdfplus/10.1162/leon.2009.42.3.197?casa_token=B7zIybTWjycAAAAA:4E5WJImhRorjMPh-yRA_pb54_OinqJzhNKNw8htGy6uVtoE2PUVty8EXIpZ1DNemFgmhUk55rw"
        },
        {
            "name" : "Bødker, S. (2015). Third-wave HCI, 10 years later: participation and sharing. *Interactions*, 22(5), 24-31.",
            "url" : "https://dl.acm.org/doi/fullHtml/10.1145/2804405"
        },
        {
            "name" : "Miranda, E. R. (2009). Preface: Aesthetic decisions in computer-aided composition. *Contemporary Music Review, 28*(2), 129-132.  https://doi.org/10.1080/07494460903327504",
            "url" : "https://doi.org/10.1080/07494460903327504"
        },
        {
            "name" : "Ohm, J. (2003). *Multimedia communication technology: Representation, transmission and identification of multimedia signals.* Springer Science & Business Media.",
            "url" : "https://www.springer.com/gp/book/9783540012498"
        },
        {
            "name" : "Carter, S., & Nielsen, M. (2017). Using artificial intelligence to augment human intelligence. *Distill, 2*(12). https://doi.org/10.23915/distill.00009",
            "url" : "https://doi.org/10.23915/distill.00009"
        },
        {
            "name" : "Stanford Research Institute. (1962). *Augmenting human intellect: A conceptual framework* (SRI Project No. 3578). Air Force Office of Scientific Research. https://apps.dtic.mil/dtic/tr/fulltext/u2/289565.pdf"
        },
        {
            "name" : "Turkle, S., & Papert, S. (1990). Epistemological pluralism: Styles and voices within the computer culture. *Signs: Journal of women in culture and society, 16*(1), 128-157.",
            "url" : "https://www.jstor.org/stable/3174610 "
        },
        {
            "name" : "Bergström, I., & Blackwell, A. F. (2016, September). The practices of programming. In *2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)* (pp. 190-198). IEEE. https://doi.org/10.1109/VLHCC.2016.7739684",
            "url" : "https://doi.org/10.1109/VLHCC.2016.7739684"
        },
        {
            "name" : "McLean, A., & Wiggins, G. A. (2010). Bricolage Programming in the Creative Arts. In *PPIG* (p. 18).",
            "url" : "https://ppig.org/papers/2010-ppig-22nd-mclean/"
        },
        {
            "name" : "De Campo, A. (2014). Lose control, gain influence: Concepts for Metacontrol. In *ICMC* (pp. 217-222). http://hdl.handle.net/2027/spo.bbp2372.2014.034",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2014.034"
        },
        {
            "name" : "Mehri, S., Kumar, K., Gulrajani, I., Kumar, R., Jain, S., Sotelo, J., ... & Bengio, Y. (2016). SampleRNN: An unconditional end-to-end neural audio generation model. *arXiv preprint arXiv:1612.07837.*",
            "url" : "https://arxiv.org/pdf/1612.07837.pdf%7D"
        },  
        {
            "name" : "Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2016). Rethinking the inception architecture for computer vision. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition* (Vol 1.) (pp. 2818-2826). https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.308",
            "url" : "https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.308"
        },
        {
            "name" : "Xenakis, I. (1992). *Formalized music: thought and mathematics in composition* (No. 6). Pendragon Press.",
            "url" : "https://books.google.co.uk/books?hl=en&lr=&id=y6lL3I0vmMwC&oi=fnd&pg=PR7&dq=Formalized+Music&ots=W-k1lzkqc1&sig=BW6uo7ievipZzHfn-ye1KPDEPZA&redir_esc=y#v=onepage&q=Formalized%20Music&f=false"
        },
        {
            "name" : "Grill, T., & Flexer, A. (2012, September). Visualization of perceptual qualities in textural sounds. In *ICMC* (pp. 589-596). http://hdl.handle.net/2027/spo.bbp2372.2012.110",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2012.110"
        },
        {
            "name" : "Grill, T. (2012). *Perceptually informed organization of textural sounds.* [Unpublished doctoral dissertation]. University of Music and Performing Arts Graz, Austria.",
            "url" : "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.722.1088&rep=rep1&type=pdf"
        },
    	{
    		"name" : "Hackbarth, B., Schnell, N., & Schwarz, D. (2010). *AudioGuide: A framework for creative exploration of concatenative sound synthesis.* Research report, IRCAM, Paris, France.",
    		"url" : "http://articles.ircam.fr/textes/Hackbarth10a/index.pdf"	
    	},
        {
            "name" : "Fitzgerald, D., Cranitch, M., & Coyle, E. (2005, July). Shifted non-negative matrix factorisation for sound source separation. In *IEEE/SP 13th Workshop on Statistical Signal Processing, 2005* (pp. 1132-1137). IEEE. https://doi.org/10.1109/SSP.2005.1628765",
            "url" : "https://doi.org/10.1109/SSP.2005.1628765"
        },
        {
            "name" : "Hennequin, R., Khlif, A., Voituret, F., & Moussallam, M. (2020). Spleeter: a fast and efficient music source separation tool with pre-trained models. *Journal of Open Source Software, 5*(50), 2154. https://doi.org/10.21105/joss.02154",
            "url" : "https://doi.org/10.21105/joss.02154"
        },
        {
            "name" : "Foote, J. (2000, July). Automatic audio segmentation using a measure of audio novelty. In *2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No. 00TH8532)* (pp. 452-455). IEEE. https://doi.org/10.1109/ICME.2000.869637",
            "url" : "https://doi.org/10.1109/ICME.2000.869637"   
        },
        {
            "name" : "Ghisi, D. (2017). *Music across music: towards a corpus-based, interactive computer-aided composition* [Unpublished doctoral dissertation]. Pierre and Mary Curie University and Sorbonne University",
            "url" : "https://www.danieleghisi.com/phd/PHDThesis_20180118.pdf"
        },
        {
            "name" : "Ajmera, J., McCowan, I. A., & Bourlard, H. (2004). *Robust audio segmentation*. [Doctoral dissertation, École Polytechnique]. EPFL. https://infoscience.epfl.ch/record/83070",
            "url" : "https://infoscience.epfl.ch/record/83070"
        },
        {
            "name" : "Eldridge, A., Casey, M., Moscoso, P., & Peck, M. (2016). A new method for ecoacoustics? Toward the extraction and evaluation of ecologically-meaningful soundscape components using sparse coding methods. *PeerJ, 4*, https://doi.org/10.7717/peerj.2108",
            "url" : "https://doi.org/10.7717/peerj.2108"
        },
        {
            "name" : "Michalakos, C. (2012). The augmented drum kit: An intuitive approach to live electronic percussion performance. In *ICMC* (pp. 257-260). http://hdl.handle.net/2027/spo.bbp2372.2012.046",
            "url" : "http://hdl.handle.net/2027/spo.bbp2372.2012.046"
        },
        {
            "name": "Fasciani, S. (2016). TSAM: A tool for analyzing, modeling, and mapping the timbre of sound synthesizers. In *Proceedings of the 13th Sound and Music Computing Conference* (pp. 129-136).",
            "url" : "https://ro.uow.edu.au/dubaipapers/752"
        },
        {
            "name" : "Hohman, F., Conlen, M., Heer, J., & Chau, D. H. P. (2020). Communicating with interactive articles. *Distill, 5*(9). https://doi.org/10.23915/distill.00028",
            "url" : "https://doi.org/10.23915/distill.00028"
        },
        {
            "name" : "Fitzgerald, D. (2010, September). Harmonic/percussive separation using median filtering. In *Proceedings of the International Conference on Digital Audio Effects (DAFx)*",
            "url" : "https://www.researchgate.net/publication/254583990_HarmonicPercussive_Separation_using_Median_Filtering"
        }
    ]
}
